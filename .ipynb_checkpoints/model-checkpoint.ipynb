{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing cifar10 dataset that comes with the keras library\n",
    "from keras.datasets import cifar10\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#function that will load non face cifar images and normalize them\n",
    "def load_non_face_images():\n",
    "    (_,_),(cifar10_images,_)=cifar10.load_data()\n",
    "    cifar10_images = cifar10_images[:60]\n",
    "    cifar10_images = cifar10_images.astype('float32')/255.0\n",
    "    return cifar10_images\n",
    "\n",
    "#function that will load face images and normalize them\n",
    "def load_face_images(dir_name):\n",
    "    output = []\n",
    "    for i in glob.glob(dir_name + '/*'):\n",
    "        image = Image.open(i).resize((32,32))\n",
    "        img_data = np.asarray(image, dtype='float32')/255.0\n",
    "        oid = np.transpose(img_data, (2,0,1))\n",
    "        output.append(oid)\n",
    "    return np.asarray(output)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to seperate face and non face data into train and test images\n",
    "def seperate_data(face_images, non_face_images):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        test_images.append(face_images[i])\n",
    "        test_labels.append([1,0])\n",
    "        test_images.append(non_face_images[i])\n",
    "        test_labels.append([0,1])\n",
    "        \n",
    "    for i in range(len(face_images)-10):\n",
    "        train_images.append(face_images[i])\n",
    "        train_labels.append([1,0])\n",
    "        train_images.append(non_face_images[i])\n",
    "        train_labels.append([0,1])\n",
    "    return np.asarray(train_images), np.asarray(train_labels), np.asarray(test_images), np.asarray(test_labels)\n",
    "\n",
    "#function to flatten an image array \n",
    "def reshape_image(input_array):\n",
    "    output_array = []\n",
    "    for image in input_array:\n",
    "        output_array.append(image.reshape(-1))\n",
    "    return np.asarray(output_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all necessary libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Reshape, Dense, Flatten, Dropout\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "K.set_learning_phase(1)\n",
    "from freeze_graph import freeze_graph\n",
    "import tensorflow as tf\n",
    "\n",
    "#functions to define, train and evaluate model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((3,32,32), input_shape = (3072,)))\n",
    "    model.add(Conv2D(32, (3,3), input_shape = (3,32,32), padding = 'same', activation ='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation = 'relu', kernel_constraint = maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation = 'softmax'))\n",
    "    return model\n",
    "\n",
    "def train_eval_model(model, train_images, train_labels):\n",
    "    epochs = 50\n",
    "    opt = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    print(model.summary)\n",
    "    model.fit(train_images, train_labels, validation_data = (train_images,train_labels), epochs = epochs, batch_size = 12)\n",
    "    \n",
    "    \n",
    "    #creating a protobuf file for android import\n",
    "    frozen_graph = freeze_graph(K.get_session(), output_names=[model.output.op.name])\n",
    "    tf.train.write_graph(frozen_graph,'.','C:/Users/Shubham/PycharmProjects/facialrecognition/protobuffile.pb',as_text=False)\n",
    "    print(model.input.op.name)\n",
    "    print(model.output.op.name)\n",
    "\n",
    "    scores = model.evaluate(train_images,train_labels, verbose = 0)\n",
    "    print(\"accuracy: %.2f%%\"%(scores[1]*100))\n",
    "    return model\n",
    "\n",
    "#A function to check our trained model\n",
    "def predict_image(model, test_images, test_labels):\n",
    "    for i in range(len(test_labels)):\n",
    "        test_image = np.expand_dims(test_images[i], axis = 0)\n",
    "        print('Predicted_label: {}, actual label: {}'.format(model.predict(test_image), test_labels[i]))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the code\n",
    "def run():\n",
    "    face_images = load_non_face_images()\n",
    "    non_face_images = load_face_images('faceimages')\n",
    "\n",
    "    train_images, train_labels, test_images, test_labels = seperate_data(face_images, non_face_images)\n",
    "    \n",
    "    train_images = reshape_image(train_images)\n",
    "    test_images = reshape_image(test_images)\n",
    "\n",
    "    model = create_model()\n",
    "    \n",
    "    model = train_eval_model(model, train_images, train_labels)\n",
    "\n",
    "    predict_image(model, test_images, test_labels)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
